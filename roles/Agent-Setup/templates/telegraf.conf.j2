# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply surround
# them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
# for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"


# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  precision = ""

  ## Log at debug level.
  # debug = false
  ## Log only error level messages.
  # quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  # logtarget = "file"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  # logfile = ""

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  # logfile_rotation_interval = "0d"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # logfile_rotation_max_size = "0MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  # logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default ansible_hostname, if empty use os.ansible_hostname()
  hostname = "{{ ansible_hostname }}"
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################


# Configuration for sending metrics to InfluxDB
[[outputs.influxdb]]
  ## The full HTTP or UDP URL for your InfluxDB instance.
  ##
  ## Multiple URLs can be specified for a single cluster, only ONE of the
  ## urls will be written to each interval.
  # urls = ["unix:///var/run/influxdb.sock"]
  # urls = ["udp://127.0.0.1:8089"]
  urls = ["http://10.0.0.121:8086"]

  ## The target database for metrics; will be created as needed.
  ## For UDP url endpoint database needs to be configured on server side.
  database = "telegraf"

  ## The value of this tag will be used to determine the database.  If this
  ## tag is not set the 'database' option is used as the default.
  # database_tag = ""

  ## If true, the 'database_tag' will not be included in the written metric.
  # exclude_database_tag = false

  ## If true, no CREATE DATABASE queries will be sent.  Set to true when using
  ## Telegraf with a user without permissions to create databases or when the
  ## database already exists.
  # skip_database_creation = false

  ## Name of existing retention policy to write to.  Empty string writes to
  ## the default retention policy.  Only takes effect when using HTTP.
  # retention_policy = ""

  ## The value of this tag will be used to determine the retention policy.  If this
  ## tag is not set the 'retention_policy' option is used as the default.
  # retention_policy_tag = ""

  ## If true, the 'retention_policy_tag' will not be included in the written metric.
  # exclude_retention_policy_tag = false

  ## Write consistency (clusters only), can be: "any", "one", "quorum", "all".
  ## Only takes effect when using HTTP.
  # write_consistency = "any"

  ## Timeout for HTTP messages.
  # timeout = "5s"

  ## HTTP Basic Auth
  username = "smondb1"
  password = "{{ secret['influx_password'] }}"

  ## HTTP User-Agent
  # user_agent = "telegraf"

  ## UDP payload size is the maximum packet size to send.
  # udp_payload = "512B"

  ## Optional TLS Config for use on HTTP connections.
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  ## Use TLS but skip chain & host verification
  # insecure_skip_verify = false

  ## HTTP Proxy override, if unset values the standard proxy environment
  ## variables are consulted to determine which proxy, if any, should be used.
  # http_proxy = "http://corporate.proxy:3128"

  ## Additional HTTP headers
  # http_headers = {"X-Special-Header" = "Special-Value"}

  ## HTTP Content-Encoding for write request body, can be set to "gzip" to
  ## compress body or "identity" to apply no encoding.
  # content_encoding = "gzip"

  ## When true, Telegraf will output unsigned integers as unsigned values,
  ## i.e.: "42u".  You will need a version of InfluxDB supporting unsigned
  ## integer values.  Enabling this option will result in field type errors if
  ## existing data has been written.
  # influx_uint_support = false


###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################

# Read metrics about cpu usage
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  report_active = false


# Read metrics about disk usage by mount point
[[inputs.disk]]
  ## By default stats will be gathered for all mount points.
  ## Set mount_points will restrict the stats to only the specified mount points.
  # mount_points = ["/"]

  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]


# Read metrics about disk IO by device
[[inputs.diskio]]
  ## By default, telegraf will gather stats for all devices including
  ## disk partitions.
  ## Setting devices will restrict the stats to the specified devices.
  # devices = ["sda", "sdb", "vd*"]
  ## Uncomment the following line if you need disk serial numbers.
  # skip_serial_number = false
  #
  ## On systems which support it, device metadata can be added in the form of
  ## tags.
  ## Currently only Linux is supported via udev properties. You can view
  ## available properties for a device by running:
  ## 'udevadm info -q property -n /dev/sda'
  ## Note: Most, but not all, udev properties can be accessed this way. Properties
  ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH.
  # device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]
  #
  ## Using the same metadata source as device_tags, you can also customize the
  ## name of the device via templates.
  ## The 'name_templates' parameter is a list of templates to try and apply to
  ## the device. The template may contain variables in the form of '$PROPERTY' or
  ## '${PROPERTY}'. The first template which does not contain any variables not
  ## present for the device is used as the device name tag.
  ## The typical use case is for LVM volumes, to get the VG/LV name instead of
  ## the near-meaningless DM-0 name.
  # name_templates = ["$ID_FS_LABEL","$DM_VG_NAME/$DM_LV_NAME"]


# Get kernel statistics from /proc/stat
[[inputs.kernel]]
  # no configuration


# Read metrics about memory usage
[[inputs.mem]]
  # no configuration


# Get the number of processes and group them by status
[[inputs.processes]]
  # no configuration


# Read metrics about swap memory usage
[[inputs.swap]]
  # no configuration


# Read metrics about system load & uptime
[[inputs.system]]
  ## Uncomment to remove deprecated metrics.
    fielddrop = ["uptime_format"]



{% if ansible_hostname == "alpha" or ansible_hostname == "bravo" or ansible_hostname == "charlie" %}
{% filter indent(width=2) %}
  # # Collects performance metrics from the MON, OSD, MDS and RGW nodes in a Ceph storage cluster.
  [[inputs.ceph]]
  #   ## This is the recommended interval to poll.  Too frequent and you will lose
  #   ## data points due to timeouts during rebalancing and recovery
      interval = '1m'
  #
  #   ## All configuration values are optional, defaults are shown below
  #
  #   ## location of ceph binary
      ceph_binary = "/usr/bin/ceph"
  #
  #   ## directory in which to look for socket files
      socket_dir = "/var/run/ceph"
  #
  #   ## prefix of MON and OSD socket files, used to determine socket type
  #   mon_prefix = "ceph-mon"
  #   osd_prefix = "ceph-osd"
  #   mds_prefix = "ceph-mds"
  #   rgw_prefix = "ceph-client"
  #
  #   ## suffix used to identify socket files
  #   socket_suffix = "asok"
  #
  #   ## Ceph user to authenticate as, ceph will search for the corresponding keyring
  #   ## e.g. client.admin.keyring in /etc/ceph, or the explicit path defined in the
  #   ## client section of ceph.conf for example:
  #   ##
  #   ##     [client.telegraf]
  #   ##         keyring = /etc/ceph/client.telegraf.keyring
  #   ##
  #   ## Consult the ceph documentation for more detail on keyring generation.
  #   ceph_user = "client.admin"
  #
  #   ## Ceph configuration to use to locate the cluster
  #   ceph_config = "/etc/ceph/ceph.conf"
  #
  #   ## Whether to gather statistics via the admin socket
  #   gather_admin_socket_stats = true
  #
  #   ## Whether to gather statistics via ceph commands, requires ceph_user and ceph_config
  #   ## to be specified
  #   gather_cluster_stats = false
{% endfilter %}
{% else %}
{% endif %}


# # Query given DNS server and gives statistics
[[inputs.dns_query]]
#   ## servers to query
    servers = ["10.0.0.116","10.0.0.117"]
#
#   ## Network is the network protocol name.
#   # network = "udp"
#
#   ## Domains or subdomains to query.
    domains = ["internal.markaplay.net"]
#
#   ## Query record type.
#   ## Possible values: A, AAAA, CNAME, MX, NS, PTR, TXT, SOA, SPF, SRV.
    record_type = "A"
#
#   ## Dns server port.
    port = 53
#
#   ## Query timeout in seconds.
    timeout = 2


{% set Docker_service = ansible_facts['docker0'] %}
{% if Docker_service is defined %}
{% filter indent(width=2) %}
  # # Read metrics about docker containers
  [[inputs.docker]]
  #   ## Docker Endpoint
  #   ##   To use TCP, set endpoint = "tcp://[ip]:[port]"
  #   ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"
  #   endpoint = "unix:///var/run/docker.sock"
  #
  #   ## Set to true to collect Swarm metrics(desired_replicas, running_replicas)
  #   gather_services = false
  #
  #   ## Only collect metrics for these containers, collect all if empty
  #   container_names = []
  #
  #   ## Set the source tag for the metrics to the container ID ansible_hostname, eg first 12 chars
  #   source_tag = false
  #
  #   ## Containers to include and exclude. Globs accepted.
  #   ## Note that an empty array for both will include all containers
  #   container_name_include = []
  #   container_name_exclude = []
  #
  #   ## Container states to include and exclude. Globs accepted.
  #   ## When empty only containers in the "running" state will be captured.
  #   ## example: container_state_include = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]
  #   ## example: container_state_exclude = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]
  #   # container_state_include = []
  #   # container_state_exclude = []
  #
  #   ## Timeout for docker list, info, and stats commands
  #   timeout = "5s"
  #
  #   ## Whether to report for each container per-device blkio (8:0, 8:1...),
  #   ## network (eth0, eth1, ...) and cpu (cpu0, cpu1, ...) stats or not.
  #   ## Usage of this setting is discouraged since it will be deprecated in favor of 'perdevice_include'.
  #   ## Default value is 'true' for backwards compatibility, please set it to 'false' so that 'perdevice_include' setting
  #   ## is honored.
  #   perdevice = true
  #
  #   ## Specifies for which classes a per-device metric should be issued
  #   ## Possible values are 'cpu' (cpu0, cpu1, ...), 'blkio' (8:0, 8:1, ...) and 'network' (eth0, eth1, ...)
  #   ## Please note that this setting has no effect if 'perdevice' is set to 'true'
  #   # perdevice_include = ["cpu"]
  #
  #   ## Whether to report for each container total blkio and network stats or not.
  #   ## Usage of this setting is discouraged since it will be deprecated in favor of 'total_include'.
  #   ## Default value is 'false' for backwards compatibility, please set it to 'true' so that 'total_include' setting
  #   ## is honored.
  #   total = false
  #
  #   ## Specifies for which classes a total metric should be issued. Total is an aggregated of the 'perdevice' values.
  #   ## Possible values are 'cpu', 'blkio' and 'network'
  #   ## Total 'cpu' is reported directly by Docker daemon, and 'network' and 'blkio' totals are aggregated by this plugin.
  #   ## Please note that this setting has no effect if 'total' is set to 'false'
  #   # total_include = ["cpu", "blkio", "network"]
  #
  #   ## Which environment variables should we use as a tag
  #   ##tag_env = ["JAVA_HOME", "HEAP_SIZE"]
  #
  #   ## docker labels to include and exclude as tags.  Globs accepted.
  #   ## Note that an empty array for both will include all labels as tags
  #   docker_label_include = []
  #   docker_label_exclude = []
  #
  #   ## Optional TLS Config
  #   # tls_ca = "/etc/telegraf/ca.pem"
  #   # tls_cert = "/etc/telegraf/cert.pem"
  #   # tls_key = "/etc/telegraf/key.pem"
  #   ## Use TLS but skip chain & host verification
  #   # insecure_skip_verify = false
{% endfilter %}
{% else %}
{% endif %}


{% if ansible_hostname == "plprimn112" %}
{% filter indent(width=2) %}
  # # Read flattened metrics from one or more GrayLog HTTP endpoints
  [[inputs.graylog]]
  #   ## API endpoint, currently supported API:
  #   ##
  #   ##   - multiple  (Ex http://<host>:12900/system/metrics/multiple)
  #   ##   - namespace (Ex http://<host>:12900/system/metrics/namespace/{namespace})
  #   ##
  #   ## For namespace endpoint, the metrics array will be ignored for that call.
  #   ## Endpoint can contain namespace and multiple type calls.
  #   ##
  #   ## Please check http://[graylog-server-ip]:12900/api-browser for full list
  #   ## of endpoints
  #   servers = [
      "http://localhost:12900/system/metrics/multiple",
  #   ]
  #
  #   ## Set timeout (default 5 seconds)
  #   # timeout = "5s"
  #
  #   ## Metrics list
  #   ## List of metrics can be found on Graylog webservice documentation.
  #   ## Or by hitting the the web service api at:
  #   ##   http://[graylog-host]:12900/system/metrics
  #   metrics = [
      "jvm.cl.loaded",
      "jvm.memory.pools.Metaspace.committed"
  #   ]
  #
  #   ## Username and password
    username = "sauditinf"
    password = "{{ GL_pass }}"
  #
  #   ## Optional TLS Config
  #   # tls_ca = "/etc/telegraf/ca.pem"
  #   # tls_cert = "/etc/telegraf/cert.pem"
  #   # tls_key = "/etc/telegraf/key.pem"
  #   ## Use TLS but skip chain & host verification
  #   # insecure_skip_verify = false
{% endfilter %}
{% else %}
{% endif %}


{% if ansible_hostname == "plpridb121" %}
{% filter indent(width=2) %}
  # # Read InfluxDB-formatted JSON metrics from one or more HTTP endpoints
  [[inputs.influxdb]]
  #   ## Works with InfluxDB debug endpoints out of the box,
  #   ## but other services can use this format too.
  #   ## See the influxdb plugin's README for more details.
  #
  #   ## Multiple URLs from which to read InfluxDB-formatted JSON
  #   ## Default is "http://localhost:8086/debug/vars".
  #   urls = [
  #     "http://localhost:8086/debug/vars"
  #   ]
  #
  #   ## Username and password to send using HTTP Basic Authentication.
      username = "smondb1"
      password = "{{ Influx_pass }}"
  #
  #   ## Optional TLS Config
  #   # tls_ca = "/etc/telegraf/ca.pem"
  #   # tls_cert = "/etc/telegraf/cert.pem"
  #   # tls_key = "/etc/telegraf/key.pem"
  #   ## Use TLS but skip chain & host verification
  #   # insecure_skip_verify = false
  #
  #   ## http request & header timeout
  #   timeout = "5s"
  {% endfilter %}
{% else %}
{% endif %}


# # Collect statistics about itself
[[inputs.internal]]
#   ## If true, collect telegraf memory stats.
    collect_memstats = true

{% if ansible_hostname == "alpha" or ansible_hostname == "tn01" or ansible_hostname == "charlie" %}
{% filter indent(width=2) %}
  # # Read metrics from the bare metal servers via IPMI
  [[inputs.ipmi_sensor]]
  #   ## optionally specify the path to the ipmitool executable
  #   # path = "/usr/bin/ipmitool"
  #   ##
  #   ## Setting 'use_sudo' to true will make use of sudo to run ipmitool.
  #   ## Sudo must be configured to allow the telegraf user to run ipmitool
  #   ## without a password.
  #   # use_sudo = false
  #   ##
  #   ## optionally force session privilege level. Can be CALLBACK, USER, OPERATOR, ADMINISTRATOR
  #   # privilege = "ADMINISTRATOR"
  #   ##
  #   ## optionally specify one or more servers via a url matching
  #   ##  [username[:password]@][protocol[(address)]]
  #   ##  e.g.
  #   ##    root:passwd@lan(127.0.0.1)
  #   ##
  #   ## if no servers are specified, local machine sensor stats will be queried
  #   ##
  #   # servers = ["USERID:PASSW0RD@lan(192.168.1.1)"]
  #
  #   ## Recommended: use metric 'interval' that is a multiple of 'timeout' to avoid
  #   ## gaps or overlap in pulled data
  #   interval = "30s"
  #
  #   ## Timeout for the ipmitool command to complete
  #   timeout = "20s"
  #
  #   ## Schema Version: (Optional, defaults to version 1)
  #   metric_version = 2
  #
  #   ## Optionally provide the hex key for the IMPI connection.
  #   # hex_key = ""
  #
  #   ## If ipmitool should use a cache
  #   ## for me ipmitool runs about 2 to 10 times faster with cache enabled on HP G10 servers (when using ubuntu20.04)
  #   ## the cache file may not work well for you if some sensors come up late
  #   # use_cache = false
  #
  #   ## Path to the ipmitools cache file (defaults to OS temp dir)
  #   ## The provided path must exist and must be writable
  #   # cache_path = ""
{% endfilter %}
{% else %}
{% endif %}

{% if ansible_hostname == "alpha" or ansible_hostname == "bravo" or ansible_hostname == "charlie" %}
{% filter indent(width=2) %}
  # # Get kernel statistics from /proc/vmstat
  [[inputs.kernel_vmstat]]
  #   # no configuration
{% endfilter %}
{% else %}
{% endif %}


# # Read metrics about network interface usage
[[inputs.net]]
#   ## By default, telegraf gathers stats from any up interface (excluding loopback)
#   ## Setting interfaces will tell it to gather these explicit interfaces,
#   ## regardless of status.
#   ##
    interfaces = ["eth0"]
#   ##
#   ## On linux systems telegraf also collects protocol stats.
#   ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.
#   ##
    ignore_protocol_stats = false
#   ##


# # Read TCP metrics such as established, time wait and sockets counts.
[[inputs.netstat]]
#   # no configuration

{% if ansible_hostname == "plprilb113" %}
{% filter indent(width=2) %}
  # # Read Nginx's basic status information (ngx_http_stub_status_module)
  [[inputs.nginx]]
  #   # An array of Nginx stub_status URI to gather stats.
  #   urls = ["http://localhost/server_status"]
  #
  #   ## Optional TLS Config
  #   tls_ca = "/etc/telegraf/ca.pem"
  #   tls_cert = "/etc/telegraf/cert.cer"
  #   tls_key = "/etc/telegraf/key.key"
  #   ## Use TLS but skip chain & host verification
      insecure_skip_verify = true
  #
  #   # HTTP response timeout (default: 5s)
  #   response_timeout = "5s"


  # # Read Nginx virtual host traffic status module information (nginx-module-sts)
  [[inputs.nginx_sts]]
  #   ## An array of ngx_http_status_module or status URI to gather stats.
      urls = ["http://localhost/status"]
  #
  #   ## HTTP response timeout (default: 5s)
  #   response_timeout = "5s"
  #
  #   ## Optional TLS Config
  #   # tls_ca = "/etc/telegraf/ca.pem"
  #   # tls_cert = "/etc/telegraf/cert.pem"
  #   # tls_key = "/etc/telegraf/key.pem"
  #   ## Use TLS but skip chain & host verification
      insecure_skip_verify = true
{% endfilter %}
{% else %}
{% endif %}

{% if ansible_hostname == "alpha" or ansible_hostname == "bravo" or ansible_hostname == "charlie" %}
{% filter indent(width=2) %}
  # # Provides metrics from Proxmox nodes (Proxmox Virtual Environment > 6.2).
  [[inputs.proxmox]]
  #   ## API connection configuration. The API token was introduced in Proxmox v6.2. Required permissions for user and token: PVEAuditor role on /.
      base_url = "https://alpha.internal.markaplay.net:8006/api2/json"
  #   api_token = "ansible@automation!TOKENID={{ Prox_token }}"
  #   ## Node name, defaults to OS ansible_hostname
      node_name = "alpha"
  #
  #   ## Optional TLS Config
  #   # tls_ca = "/etc/telegraf/ca.pem"
  #   # tls_cert = "/etc/telegraf/cert.pem"
  #   # tls_key = "/etc/telegraf/key.pem"
  #   ## Use TLS but skip chain & host verification
      insecure_skip_verify = false
  #
  #   # HTTP response timeout (default: 5s)
  #   response_timeout = "5s"
{% endfilter %}
{% else %}
{% endif %}


# # Reads last_run_summary.yaml file and converts to measurements
# [[inputs.puppetagent]]
#   ## Location of puppet last run summary file
#   location = "/var/lib/puppet/state/last_run_summary.yaml"

{% if ansible_hostname == "alpha" or ansible_hostname == "bravo" or ansible_hostname == "charlie" or ansible_hostname == "tn01" %}
{% filter indent(width=2) %}
  # # Monitor sensors, requires lm-sensors package
  [[inputs.sensors]]
  #   ## Remove numbers from field names.
  #   ## If true, a field name like 'temp1_input' will be changed to 'temp_input'.
      remove_numbers = false
  #
  #   ## Timeout is the maximum amount of time that the sensors command can run.
  #    timeout = "5s"
{% endfilter %}
{% else %}
{% endif %}


# # Gather systemd units state
[[inputs.systemd_units]]
#   ## Set timeout for systemctl execution
#   # timeout = "1s"
#   #
#   ## Filter for a specific unit type, default is "service", other possible
#   ## values are "socket", "target", "device", "mount", "automount", "swap",
#   ## "timer", "path", "slice" and "scope ":
    unittype = "service"
#   #
#   ## Filter for a specific pattern, default is "" (i.e. all), other possible
#   ## values are valid pattern for systemctl, e.g. "a*" for all units with
#   ## names starting with "a"
#   # pattern = ""
#   ## pattern = "telegraf* influxdb*"
#   ## pattern = "a*"

{% if ansible_hostname == 'tn01' or ansible_hostname == "pbs" %}
{% filter indent(width=2) %}
  # # Read metrics of ZFS from arcstats, zfetchstats, vdev_cache_stats, pools and datasets
  [[inputs.zfs]]
  #   ## ZFS kstat path. Ignored on FreeBSD
  #   ## If not specified, then default is:
  #   # kstatPath = "/proc/spl/kstat/zfs"
  #
  #   ## By default, telegraf gather all zfs stats
  #   ## If not specified, then default is:
  #   # kstatMetrics = ["arcstats", "zfetchstats", "vdev_cache_stats"]
  #   ## For Linux, the default is:
  #   # kstatMetrics = ["abdstats", "arcstats", "dnodestats", "dbufcachestats",
  #   #   "dmu_tx", "fm", "vdev_mirror_stats", "zfetchstats", "zil"]
  #   ## By default, don't gather zpool stats
  #   # poolMetrics = false
  #   ## By default, don't gather zdataset stats
  #   # datasetMetrics = false
{% endfilter %}
{% else %}
{% endif %}


###############################################################################
#                            SERVICE INPUT PLUGINS                            #
###############################################################################

{% if Docker_service is defined %}
{% filter indent(width=2) %}
  # # Read logging output from the Docker engine
  [[inputs.docker_log]]
  #   ## Docker Endpoint
  #   ##   To use TCP, set endpoint = "tcp://[ip]:[port]"
  #   ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"
      endpoint = "unix:///var/run/docker.sock"
  #
  #   ## When true, container logs are read from the beginning; otherwise
  #   ## reading begins at the end of the log.
  #   # from_beginning = false
  #
  #   ## Timeout for Docker API calls.
  #   # timeout = "5s"
  #
  #   ## Containers to include and exclude. Globs accepted.
  #   ## Note that an empty array for both will include all containers
  #   # container_name_include = []
  #   # container_name_exclude = []
  #
  #   ## Container states to include and exclude. Globs accepted.
  #   ## When empty only containers in the "running" state will be captured.
  #   # container_state_include = []
  #   # container_state_exclude = []
  #
  #   ## docker labels to include and exclude as tags.  Globs accepted.
  #   ## Note that an empty array for both will include all labels as tags
  #   # docker_label_include = []
  #   # docker_label_exclude = []
  #
  #   ## Set the source tag for the metrics to the container ID ansible_hostname, eg first 12 chars
  #   source_tag = false
  #
  #   ## Optional TLS Config
  #   # tls_ca = "/etc/telegraf/ca.pem"
  #   # tls_cert = "/etc/telegraf/cert.pem"
  #   # tls_key = "/etc/telegraf/key.pem"
  #   ## Use TLS but skip chain & host verification
      insecure_skip_verify = true
{% endfilter %}
{% else %}
{% endif %}


{% if ansible_hostname == "plpridb121" %}
{% filter indent(width=2) %}
  # # Accept metrics over InfluxDB 1.x HTTP API
  [[inputs.influxdb_listener]]
  #   ## Address and port to host InfluxDB listener on
      service_address = ":8186"
  #
  #   ## maximum duration before timing out read of the request
  #   read_timeout = "10s"
  #   ## maximum duration before timing out write of the response
  #   write_timeout = "10s"
  #
  #   ## Maximum allowed HTTP request body size in bytes.
  #   ## 0 means to use the default of 32MiB.
  #   max_body_size = "32MiB"
  #
  #   ## Optional tag name used to store the database.
  #   ## If the write has a database in the query string then it will be kept in this tag name.
  #   ## This tag can be used in downstream outputs.
  #   ## The default value of nothing means it will be off and the database will not be recorded.
  #   # database_tag = ""
  #
  #   ## If set the retention policy specified in the write query will be added as
  #   ## the value of this tag name.
  #   # retention_policy_tag = ""
  #
  #   ## Set one or more allowed client CA certificate file names to
  #   ## enable mutually authenticated TLS connections
  #   tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]
  #
  #   ## Add service certificate and key
  #   tls_cert = "/etc/telegraf/cert.pem"
  #   tls_key = "/etc/telegraf/key.pem"
  #
  #   ## Optional username and password to accept for HTTP basic authentication.
  #   ## You probably want to make sure you have TLS configured above for this.
  #   # basic_username = "foobar"
  #   # basic_password = "barfoo"
{% endfilter %}
{% else %}
{% endif %}